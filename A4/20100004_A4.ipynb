{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Assignment_4.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfFXEVniY0WJ",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 4 CS 5316 Natural Language Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rh7F52CY11g",
        "colab_type": "code",
        "outputId": "e8096f12-74ea-488a-86aa-035f51c6fe69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "#Mount your google drive to this notebook\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7G4mt6rfpD4",
        "colab_type": "code",
        "outputId": "794934b5-183c-4892-b4b5-20bb95283d8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/gdrive/My Drive/NLP/Assignment4"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1QU-Nm928liikIV4AYyrX-UOUxKStNUk_/NLP/Assignment4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IFyfl4DY0WK",
        "colab_type": "code",
        "outputId": "41e24b93-7b53-4cd1-e42b-ade5a25f4e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "# Get the interactive Tools for Matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from sklearn.decomposition import PCA\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.utils.extmath import randomized_svd\n",
        "from nltk import ngrams\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Activation, RepeatVector,Flatten, TimeDistributed, Input,Bidirectional,LocallyConnected1D,Conv1D,GlobalAveragePooling1D,GlobalMaxPooling1D,Concatenate,BatchNormalization\n",
        "from tensorflow.keras.layers import Embedding, LSTM ,Dropout,GRU,SimpleRNN\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import optimizers\n",
        "# from tensorflow.keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# import tensorflow.keras.utils.to_categorical as to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "import math\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3C6wL5TY0WQ",
        "colab_type": "text"
      },
      "source": [
        "# Final Assingmnet\n",
        "This is going to be the final assignment for deep learning. Here is a very good visual for what you will be doing with\n",
        "<a href=\"https://ibb.co/mh9Ks0j\">deep learning.</a> Lets get started......."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn545-S6Y0WS",
        "colab_type": "text"
      },
      "source": [
        "# TASK 1 Paraphrase Detection\n",
        "For this task we will be using the [ Microsoft Research Paraphrase Corpus ](https://www.microsoft.com/en-us/download/details.aspx?id=52398). The corpus consist of sentence pairs with 1 or 0 labels which identify if the sentences are paraphrase or not respectively.\n",
        "<br>\n",
        "To perform this task we will be using recurrenct neural network for this task specifically the [LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/). RNN can be architected in multiple ways. Some of the possible ways are as follows:\n",
        "<img src=\"archetecturernn.png\">\n",
        "The box in the bottom is the input, followed by the hidden layer (as the middle box), and the box on top is the output layer. The one-to-one architecture is the typical neural network (<i>vanila/Feed Forward</i>) with a hidden layer between the input and the output layer. Example uses of the above archetecture are as follows:\n",
        "<ul>\n",
        "    <li>One-to-many: input is an image and outputs are image captions</li>\n",
        "    <li>Many-to-one: input is a movie's review <i>multiple words in input</i> and output is sentiment associated with the review <i>(we will be using a similar archetecture for our purpose)</i></li>\n",
        "    <li>Many-to-many: machine translation of a sentence in one language to a sentence in another language, POS tagging etc</li>\n",
        "</ul>\n",
        "<br>\n",
        "For this task we will also be using pre-trained word embeddings specificallly <a href=\"https://nlp.stanford.edu/projects/glove/\">(GloVe Embeddings)</a>. Please download the paraphrase <a href=\"https://www.microsoft.com/en-us/download/details.aspx?id=52398\">dataset</a> and glove.6B.zip from <a href=\"https://nlp.stanford.edu/projects/glove/\">here</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QojvGy-ZY0WT",
        "colab_type": "text"
      },
      "source": [
        "For this task you are required to implement the following archetecture, please use [keras functional API](https://www.tensorflow.org/guide/keras/functional) :\n",
        "<img src=\"paraphrase.png\">\n",
        "If <a href=\"https://ibb.co/RSSjRM0\">this</a> is you reaction after seeing the model archetecture dont worry we'll explain.\n",
        "The model works as follows, there will be two inputs layers, one for each sentence followed by <b>shared</b> embedding layer which feed thier outputs to the shared LSTM, <b>take the final hidden state output</b> of both LSTM's and concatenate them. Finally feed the concatenated vector to a softmax output layer for classification.\n",
        "<br>\n",
        "<i>(The reason for using one shared embedding and LSTM layer so that the model learns sentence representation for all sentence pairs(x,x') in the dataset. If we were using two seperate LSTMS for x and x' we would need to double the dataset by having both (x,x') and (x',x) pairs so that both LSTM's see the entire train data distribution)</i>\n",
        "The purpose for each layer in the model is as follows:\n",
        "<ul>\n",
        "    <li>Input takes the input sequences and feeds it to the next(you will need to specify the maximum size of a sentence as a parameter of this layer)</li>\n",
        "    <li>Embedding layer, this layer takes the sequence input then for each word in the sequence generates a fixed size vector <i>(word embedding)</i>, this layer can be trained from scratch or can be configured to use pretrained embeddings with or without fine tuning. </li>\n",
        "    <li>LSTM process the embedding vector sequences and at each step generates a hidden state vector(h)and cell memory vector(C)(<i>see diagram</i>), the keras LSTM layer returns three outputs (1) All the hidden states,(2) The final hidden state and (3) The final cell memory state<img src=\"lstm.png\"></li>\n",
        "    <li>The concatenation layer combines multple vectors into a single vector</li>\n",
        "    <li>Finally the output layer predicts if sentence pairs were paraphrase or not</li>\n",
        "</ul>\n",
        "<b>Please refer to the TF-keras documentation for all the layers <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers\">here</a></b>\n",
        "<br><br><br>\n",
        "Now that you understand the theoritical foundation for our approach lets move onto practical implementation.<br>\n",
        "<h3>Data Preperation</h3>\n",
        "\n",
        "<ul>\n",
        "    <li> First we need to preprocess the data, convert the data to lower casing. Any other preprocessing procedures are optional but keep in mind that this will affect the performance of your model.</li>\n",
        "    <li> To make training faster we will fix the maximum sequence length to 20 truncate the longer sequences.</li>\n",
        "    <li> Split the data into test, train and validation in the ratio 20,70,10. Use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">scikit_test_train_split</a> <br><i><b>Hint:</b> use the splitter twice to get desired data splits.</i></li>\n",
        "    <li> Next we need the vocabulary, vocabulary size and to convert sentences to numeric sequences by representing each word with a numeric value which will make our implementation easier later on, use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\">Tokenizer</a> from keras. <br><i>(Fit the tokenizer on train data and use the same tokenizer to convert train,test and validation data to numeric sequences)</i> </li>\n",
        "    <li>  Use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\"> pad sequences</a> to add post padding to all sentences that are shorter than maximum sequence length\n",
        "        <i>(<b>extra info</b>: fit_on_text reserves value/index 0 for padding and assigns numeric value to words starting from index 1)</i></li>\n",
        "</ul>\n",
        "<h3>Loading embeddings</h3>\n",
        "<ul>\n",
        "    <li> To use pretrained embeddings in tf keras embedding layer requires a dictionary, we need to create a dictionary whose keys will be numeric word representations and values will be the embedding vectors.</li>\n",
        "    <li> First step is to load the word embedding pairs from the glove file into a dictionary.</li>\n",
        "    <li> Next we will create a dictionary for our dataset's vocabulary. Copy all the word embeddings for words that are in our vocabulary and in the glove dictionary, if a word exists in our vocabulary but does not exist in glove dictionary create a zero vector of embedding dimension size and add it to the dictionary.</li>\n",
        "</ul>\n",
        "<h3>Create Model</h3>\n",
        "<ul>\n",
        "    <li> Create the model using <a href\"https://www.tensorflow.org/guide/keras/functional\">functional API</a></li>\n",
        "    <li> Hints: The emebedding layer has a parameter that allows you to use pretrained embeddings, for shared layers read the section of shared layer weights in function API docs</li>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ig0vpybY0WU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData(filename):\n",
        "    \"\"\"\n",
        "    Return preprocessed data\n",
        "    \n",
        "    Returns: X and Y where X is pair of sentence (x,x') and y is the label 0 or 1\n",
        "    \"\"\"\n",
        "    df =  pd.read_csv(filename)\n",
        "    df.columns = ['target','id1','id2','s1','s2']\n",
        "    del df['id1']\n",
        "    del df['id2']\n",
        "    df.head()\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhzngOFxY0Wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(data):\n",
        "    \"\"\"\n",
        "    Return preprocessed data\n",
        "\n",
        "    Args:\n",
        "        data : sentence pairs\n",
        "    \n",
        "    Returns: preprocessed_data\n",
        "    preprocessed_data : preprocessed dataset \n",
        "    \"\"\"\n",
        "    #Doing the bare minimum pre-processing. Rest to be done in tokenizer/padding \n",
        "    data['s1'] = data['s1'].str.lower()\n",
        "    data['s2'] = data['s2'].str.lower()\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d99bO_QY0Wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = loadData(\"msr_paraphrase_train.csv\")\n",
        "df_train = preprocessing(df_train)\n",
        "df_test = loadData(\"msr_paraphrase_test.csv\")\n",
        "df_test = preprocessing(df_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWLLU7y9Y0Wp",
        "colab_type": "text"
      },
      "source": [
        "### Test train split\n",
        "Use test train split from sklearn.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH4qi_MlY0Wq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testTrainSplit(data_X,data_Y):\n",
        "    \"\"\"\n",
        "    Return test train data\n",
        "\n",
        "    Args:\n",
        "        data_X : sentence pairs\n",
        "        data_Y: labels\n",
        "        \n",
        "    Returns: test train and validation split data \n",
        "    \"\"\"\n",
        "    #As asked in the email use only split the training into train and val. Use test as it is\n",
        "    X_train, X_val, y_train, y_val = train_test_split(data_X, data_Y, test_size=0.1, random_state=1)\n",
        "    return X_train,X_val,y_train,y_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYwlBt_KY0Wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_val,y_train,y_val = testTrainSplit(df_train[['s1','s2']],df_train[['target']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k50BmqAhY0W0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test,y_test = df_test[['s1','s2']],df_test[['target']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci4FePkKY0W7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combineList(X,first):\n",
        "    #Joining the sentences into a list of list \n",
        "    slist = []\n",
        "    if first:\n",
        "        newSentences = X['s1']+' '+X['s2']\n",
        "    else:\n",
        "        newSentences = X['s2']+' '+X['s1']\n",
        "    for val in newSentences:\n",
        "        slist.append(str(val))\n",
        "    return slist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onydJzjRY0W-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "listX_train1 = combineList(X_train,first=True)\n",
        "listX_test1 = combineList(X_test,first=True)\n",
        "listX_val1 = combineList(X_val,first=True)\n",
        "listX_train2 = combineList(X_train,first=False)\n",
        "listX_test2 = combineList(X_test,first=False)\n",
        "listX_val2 = combineList(X_val,first=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOi9TyIEY0XC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_trainhot = to_categorical(y_train)\n",
        "y_testhot = to_categorical(y_test)\n",
        "y_valhot = to_categorical(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZytpuSyY0XQ",
        "colab_type": "text"
      },
      "source": [
        "Implement the step regarding keras Tokenizer in the cell below.<br>\n",
        "<i> Keep in mind that each example is a pair/tupple of sentence(x,x'), combine them into a single sentence so that your data is a list of sentences before calling fit on text(Tokenizer). There is out of vocabulary option in tokenizer check that out aswell.</i>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knGA3bTDY0XR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get vocabular, vocabulary size and numeric word seqeunces for train,test and validation data\n",
        "def doMagic(listX_train,listX_test,listX_val,maxlen=20):\n",
        "    text_tokenizer = Tokenizer(lower=False,oov_token=\"<UNK>\")\n",
        "    text_tokenizer.fit_on_texts(listX_train)\n",
        "    #Done creating sequences \n",
        "    sequence_X_train = text_tokenizer.texts_to_sequences(listX_train)\n",
        "    sequence_X_test = text_tokenizer.texts_to_sequences(listX_test)\n",
        "    sequence_X_val = text_tokenizer.texts_to_sequences(listX_val)\n",
        "    #print(sequence_X_val)\n",
        "    #Now need to create padded sequences\n",
        "    padded_X_train = pad_sequences(sequence_X_train,maxlen=maxlen,padding=\"post\")\n",
        "    padded_X_test = pad_sequences(sequence_X_test,maxlen=maxlen,padding=\"post\")\n",
        "    padded_X_val = pad_sequences(sequence_X_val,maxlen=maxlen,padding=\"post\")\n",
        "    vocab = text_tokenizer.index_word\n",
        "    vocab_size = len(vocab)+1\n",
        "    #print(padded_X_train.shape)\n",
        "    return padded_X_train,padded_X_test,padded_X_val,vocab,vocab_size\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXXdAE12Y0XU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9diFJzLY0Xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_X_train1,padded_X_test1,padded_X_val1,vocab,vocab_size = doMagic(listX_train1,listX_test1,listX_val1,maxlen)\n",
        "padded_X_train2,padded_X_test2,padded_X_val2,_,_ = doMagic(listX_train2,listX_test2,listX_val2,maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOY5TaGWY0Xk",
        "colab_type": "text"
      },
      "source": [
        "Create the model in the cell below:\n",
        "Try out different sizes for LSTM 50,100,300 and use relu activations. Also report results with Bi-LSTM as well.<br>\n",
        "<i>To boost performance you can try adding a hidden layer between the lstm and output layer and also by adding a dropout layer in between different layers</i>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clxyec4MY0Xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "EMBEDDING_DIM = 50\n",
        "LSTM_SIZE = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dNuQ_aDY0Xp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadGlove(name,EMBEDDING_DIM,word_index):\n",
        "    embeddings_index = {}\n",
        "    f = open(name,encoding=\"utf-8\")\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    print('Found %s word vectors.' % len(embeddings_index))\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6esjJt0Y0Xx",
        "colab_type": "code",
        "outputId": "0418d759-b32c-4a0b-ed13-c4dcb4191333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix = loadGlove(\"glove.6B.50d.txt\",EMBEDDING_DIM=EMBEDDING_DIM,word_index=vocab)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_YqDv2nK9Pc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d1c4a00-0e35-40d7-f128-41e8f7abca49"
      },
      "source": [
        "type(embedding_matrix)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee3qa4ENY0X1",
        "colab_type": "code",
        "outputId": "fee05019-b5f2-4c47-a53a-cd1318b53b1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "# code model here\n",
        "%cd /content/gdrive/My Drive/NLP/Assignment4\n",
        "EMBEDDING_DIM = 50\n",
        "LSTM_SIZE = 50\n",
        "embedding_matrix = loadGlove(\"glove.6B.50d.txt\",EMBEDDING_DIM=EMBEDDING_DIM,word_index=vocab)\n",
        "inputA = Input(shape=(maxlen,))\n",
        "inputB = Input(shape=(maxlen,))\n",
        "embedding_layer = Embedding(input_dim=vocab_size,output_dim=EMBEDDING_DIM,input_length=maxlen,weights=[embedding_matrix],\n",
        "                           trainable=True)\n",
        "shared_embedding_layer_1 = embedding_layer(inputA)\n",
        "shared_embedding_layer_2 = embedding_layer(inputB)\n",
        "\n",
        "shared_lstm = LSTM(LSTM_SIZE, return_sequences=True,return_state=True,recurrent_dropout=0.2)\n",
        "_,last1,_ = shared_lstm(shared_embedding_layer_1)\n",
        "_,last2,_ = shared_lstm(shared_embedding_layer_2)\n",
        "concat = Concatenate()([last1,last2])\n",
        "out = Dense(2,activation = \"softmax\",name=\"model1\",)(concat)\n",
        "\n",
        "model = Model(inputs=[inputA,inputB],outputs=out)\n",
        "model.summary()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1QU-Nm928liikIV4AYyrX-UOUxKStNUk_/NLP/Assignment4\n",
            "Found 400000 word vectors.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 20, 50)       651450      input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 20, 50), (No 20200       embedding[0][0]                  \n",
            "                                                                 embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 100)          0           lstm[0][1]                       \n",
            "                                                                 lstm[1][1]                       \n",
            "__________________________________________________________________________________________________\n",
            "model1 (Dense)                  (None, 2)            202         concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 671,852\n",
            "Trainable params: 671,852\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRNpXNzpY0X-",
        "colab_type": "code",
        "outputId": "3e47d328-8def-4f85-c206-01f47150d554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/gdrive/My Drive/Results\n",
        "model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "filepath = \"setting_\" + \"model1\" + \".hdf5\"\n",
        "logfilepath = \"setting_\"+\"model1\" + \".csv\"\n",
        "reduce_lr_rate=0.2\n",
        "logCallback = CSVLogger(logfilepath, separator=',', append=False)\n",
        "earlyStopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=0, mode='auto')\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_weights_only=True, verbose=1,\n",
        "                             save_best_only=True, mode='auto')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=reduce_lr_rate, patience=10,\n",
        "                              cooldown=0, min_lr=0.0000000001, verbose=0)\n",
        "\n",
        "callbacks_list = [logCallback, earlyStopping, reduce_lr, checkpoint]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSNE3ftrY0YB",
        "colab_type": "code",
        "outputId": "c7efc665-a6bc-4a45-b893-e428aedc6dad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        }
      },
      "source": [
        "model.fit([padded_X_train1,padded_X_train2],y_trainhot,epochs=100, batch_size=32,\n",
        "                verbose=1,shuffle=True,callbacks=callbacks_list,\n",
        "             validation_data=([padded_X_val1,padded_X_val2],y_valhot),use_multprocessing=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.6206 - accuracy: 0.6832\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.69853, saving model to setting_model1.hdf5\n",
            "115/115 [==============================] - 17s 147ms/step - loss: 0.6206 - accuracy: 0.6832 - val_loss: 0.6032 - val_accuracy: 0.6985 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.8146\n",
            "Epoch 00002: val_accuracy did not improve from 0.69853\n",
            "115/115 [==============================] - 16s 138ms/step - loss: 0.4158 - accuracy: 0.8146 - val_loss: 0.7376 - val_accuracy: 0.6789 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.9299\n",
            "Epoch 00003: val_accuracy did not improve from 0.69853\n",
            "115/115 [==============================] - 16s 139ms/step - loss: 0.1806 - accuracy: 0.9299 - val_loss: 1.1005 - val_accuracy: 0.6201 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.9670\n",
            "Epoch 00004: val_accuracy did not improve from 0.69853\n",
            "115/115 [==============================] - 16s 139ms/step - loss: 0.0930 - accuracy: 0.9670 - val_loss: 0.9990 - val_accuracy: 0.6422 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9812\n",
            "Epoch 00005: val_accuracy did not improve from 0.69853\n",
            "115/115 [==============================] - 16s 140ms/step - loss: 0.0650 - accuracy: 0.9812 - val_loss: 1.3912 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9880\n",
            "Epoch 00006: val_accuracy did not improve from 0.69853\n",
            "115/115 [==============================] - 16s 139ms/step - loss: 0.0392 - accuracy: 0.9880 - val_loss: 1.3083 - val_accuracy: 0.6593 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9891\n",
            "Epoch 00007: val_accuracy did not improve from 0.69853\n",
            "115/115 [==============================] - 16s 137ms/step - loss: 0.0400 - accuracy: 0.9891 - val_loss: 1.6966 - val_accuracy: 0.6569 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9902\n",
            "Epoch 00008: val_accuracy did not improve from 0.69853\n",
            "115/115 [==============================] - 16s 137ms/step - loss: 0.0403 - accuracy: 0.9902 - val_loss: 1.3877 - val_accuracy: 0.6593 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9935\n",
            "Epoch 00009: val_accuracy did not improve from 0.69853\n",
            "115/115 [==============================] - 16s 137ms/step - loss: 0.0298 - accuracy: 0.9935 - val_loss: 1.3893 - val_accuracy: 0.6569 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9935\n",
            "Epoch 00010: val_accuracy did not improve from 0.69853\n",
            "115/115 [==============================] - 16s 139ms/step - loss: 0.0227 - accuracy: 0.9935 - val_loss: 1.5778 - val_accuracy: 0.6544 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9954\n",
            "Epoch 00011: val_accuracy did not improve from 0.69853\n",
            "115/115 [==============================] - 16s 138ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 2.1170 - val_accuracy: 0.6397 - lr: 0.0010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc28ee25a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj1phORzknZO",
        "colab_type": "code",
        "outputId": "1b64baa0-3fb7-4338-9130-9be604718496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "#predictions = code here\n",
        "labelList=[0,1]\n",
        "predictions = model.predict([padded_X_test1,padded_X_test2])\n",
        "from sklearn.metrics import confusion_matrix\n",
        "predictions = np.argmax(predictions,axis=-1)\n",
        "test_Y_max=np.argmax(y_testhot, axis=-1)\n",
        "cm=confusion_matrix(test_Y_max,predictions)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "cm = pd.DataFrame(cm, labelList,labelList )# matrix,names row,names col,\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(cm, annot=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc22361a8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsdKgbrFyWjr",
        "colab_type": "code",
        "outputId": "04524933-dcbd-45cd-f188-e657a443d54c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "print(\"Classification Report\\n\",classification_report(test_Y_max, predictions, labels=[0,1], target_names = [\"Positive\",\"Negative\"]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.43      0.42      0.42       578\n",
            "    Negative       0.71      0.73      0.72      1147\n",
            "\n",
            "    accuracy                           0.62      1725\n",
            "   macro avg       0.57      0.57      0.57      1725\n",
            "weighted avg       0.62      0.62      0.62      1725\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXbsDoCPkIS4",
        "colab_type": "code",
        "outputId": "2a880637-7afa-4f47-bae4-fbc8aa3e48b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "# code model here\n",
        "%cd /content/gdrive/My Drive/NLP/Assignment4\n",
        "EMBEDDING_DIM = 200\n",
        "LSTM_SIZE = 200\n",
        "embedding_matrix = loadGlove(\"glove.6B.200d.txt\",EMBEDDING_DIM=EMBEDDING_DIM,word_index=vocab)\n",
        "inputA = Input(shape=(maxlen,))\n",
        "inputB = Input(shape=(maxlen,))\n",
        "embedding_layer = Embedding(input_dim=vocab_size,output_dim=EMBEDDING_DIM,input_length=maxlen,weights=[embedding_matrix],\n",
        "                           trainable=True)\n",
        "shared_embedding_layer_1 = embedding_layer(inputA)\n",
        "shared_embedding_layer_2 = embedding_layer(inputB)\n",
        "\n",
        "shared_lstm = LSTM(LSTM_SIZE, return_sequences=True,return_state=True,recurrent_dropout=0.2)\n",
        "_,last1,_= shared_lstm(shared_embedding_layer_1)\n",
        "_,last2,_ = shared_lstm(shared_embedding_layer_2)\n",
        "concat = Concatenate()([last1,last2])\n",
        "out = Dense(2,activation = \"softmax\",name=\"model1\",)(concat)\n",
        "\n",
        "model = Model(inputs=[inputA,inputB],outputs=out)\n",
        "model.summary()\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1QU-Nm928liikIV4AYyrX-UOUxKStNUk_/NLP/Assignment4\n",
            "Found 400000 word vectors.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 20, 200)      2605800     input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 20, 200), (N 320800      embedding_1[0][0]                \n",
            "                                                                 embedding_1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 400)          0           lstm_1[0][1]                     \n",
            "                                                                 lstm_1[1][1]                     \n",
            "__________________________________________________________________________________________________\n",
            "model1 (Dense)                  (None, 2)            802         concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 2,927,402\n",
            "Trainable params: 2,927,402\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6rRcadhjoXy",
        "colab_type": "code",
        "outputId": "9832ed7e-d87a-4cf6-e9e8-6d609ff2affd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        }
      },
      "source": [
        "%cd /content/gdrive/My Drive/Results\n",
        "model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "filepath = \"setting_\" + \"model2\" + \".hdf5\"\n",
        "logfilepath = \"setting_\"+\"model2\" + \".csv\"\n",
        "reduce_lr_rate=0.2\n",
        "logCallback = CSVLogger(logfilepath, separator=',', append=False)\n",
        "earlyStopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=0, mode='auto')\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_weights_only=True, verbose=1,\n",
        "                             save_best_only=True, mode='auto')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=reduce_lr_rate, patience=10,\n",
        "                              cooldown=0, min_lr=0.0000000001, verbose=0)\n",
        "\n",
        "callbacks_list = [logCallback, earlyStopping, reduce_lr, checkpoint]\n",
        "model.fit([padded_X_train1,padded_X_train2],y_trainhot,epochs=100, batch_size=32,\n",
        "                verbose=1,shuffle=True,callbacks=callbacks_list,\n",
        "             validation_data=([padded_X_val1,padded_X_val2],y_valhot),use_multprocessing=True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Results\n",
            "Epoch 1/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.6133 - accuracy: 0.6878\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.69608, saving model to setting_model2.hdf5\n",
            "115/115 [==============================] - 19s 169ms/step - loss: 0.6133 - accuracy: 0.6878 - val_loss: 0.6018 - val_accuracy: 0.6961 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.3756 - accuracy: 0.8405\n",
            "Epoch 00002: val_accuracy did not improve from 0.69608\n",
            "115/115 [==============================] - 18s 157ms/step - loss: 0.3756 - accuracy: 0.8405 - val_loss: 0.8637 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9422\n",
            "Epoch 00003: val_accuracy did not improve from 0.69608\n",
            "115/115 [==============================] - 18s 155ms/step - loss: 0.1569 - accuracy: 0.9422 - val_loss: 0.8483 - val_accuracy: 0.5907 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9733\n",
            "Epoch 00004: val_accuracy did not improve from 0.69608\n",
            "115/115 [==============================] - 18s 157ms/step - loss: 0.0833 - accuracy: 0.9733 - val_loss: 1.4045 - val_accuracy: 0.6127 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9869\n",
            "Epoch 00005: val_accuracy did not improve from 0.69608\n",
            "115/115 [==============================] - 18s 157ms/step - loss: 0.0471 - accuracy: 0.9869 - val_loss: 1.1583 - val_accuracy: 0.6348 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9915\n",
            "Epoch 00006: val_accuracy did not improve from 0.69608\n",
            "115/115 [==============================] - 18s 157ms/step - loss: 0.0300 - accuracy: 0.9915 - val_loss: 1.4196 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9935\n",
            "Epoch 00007: val_accuracy did not improve from 0.69608\n",
            "115/115 [==============================] - 18s 157ms/step - loss: 0.0182 - accuracy: 0.9935 - val_loss: 1.9054 - val_accuracy: 0.6446 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9962\n",
            "Epoch 00008: val_accuracy did not improve from 0.69608\n",
            "115/115 [==============================] - 18s 158ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 2.1701 - val_accuracy: 0.6446 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9956\n",
            "Epoch 00009: val_accuracy did not improve from 0.69608\n",
            "115/115 [==============================] - 18s 158ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 1.7197 - val_accuracy: 0.6373 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9970\n",
            "Epoch 00010: val_accuracy did not improve from 0.69608\n",
            "115/115 [==============================] - 18s 157ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 2.1875 - val_accuracy: 0.6642 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9937\n",
            "Epoch 00011: val_accuracy did not improve from 0.69608\n",
            "115/115 [==============================] - 18s 157ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 1.5378 - val_accuracy: 0.6275 - lr: 0.0010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc222eefb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmot8inGY0YE",
        "colab_type": "text"
      },
      "source": [
        "Use the <b>model.predict</b> method to get predictions. There predictions will be a probability distribution over the lables, to get the desired class take the max value in a prediction vector as the predicted class.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2g0MJCvY0YF",
        "colab_type": "code",
        "outputId": "58d78720-05fd-4e36-a249-2243fde6bfc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "#predictions = code here\n",
        "labelList=[0,1]\n",
        "predictions = model.predict([padded_X_test1,padded_X_test2])\n",
        "from sklearn.metrics import confusion_matrix\n",
        "predictions = np.argmax(predictions,axis=-1)\n",
        "test_Y_max=np.argmax(y_testhot, axis=-1)\n",
        "cm=confusion_matrix(test_Y_max,predictions)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "cm = pd.DataFrame(cm, labelList,labelList )# matrix,names row,names col,\n",
        "plt.figure(figsize=(10,7))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(cm, annot=True, annot_kws={\"size\": 11}, fmt=\".2f\") # font size\n",
        "plt.show()\n",
        "print(cm)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "          0         1\n",
            "0  0.410035  0.589965\n",
            "1  0.264167  0.735833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBj0p1wCY0YI",
        "colab_type": "code",
        "outputId": "24182037-785b-4d6c-bb6f-33247de2281d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "print(\"Classification Report\\n\",classification_report(test_Y_max, predictions, labels=[0,1], target_names = [\"Positive\",\"Negative\"]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.44      0.41      0.42       578\n",
            "    Negative       0.71      0.74      0.72      1147\n",
            "\n",
            "    accuracy                           0.63      1725\n",
            "   macro avg       0.58      0.57      0.57      1725\n",
            "weighted avg       0.62      0.63      0.62      1725\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzUC9lpQqSus",
        "colab_type": "code",
        "outputId": "707418b9-cb35-4c14-d84b-19a3647b8321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "# code model here\n",
        "%cd /content/gdrive/My Drive/NLP/Assignment4\n",
        "EMBEDDING_DIM = 300\n",
        "LSTM_SIZE = 300\n",
        "embedding_matrix = loadGlove(\"glove.6B.300d.txt\",EMBEDDING_DIM=EMBEDDING_DIM,word_index=vocab)\n",
        "inputA = Input(shape=(maxlen,))\n",
        "inputB = Input(shape=(maxlen,))\n",
        "embedding_layer = Embedding(input_dim=vocab_size,output_dim=EMBEDDING_DIM,input_length=maxlen,weights=[embedding_matrix],\n",
        "                           trainable=True)\n",
        "shared_embedding_layer_1 = embedding_layer(inputA)\n",
        "shared_embedding_layer_2 = embedding_layer(inputB)\n",
        "\n",
        "shared_lstm = Bidirectional(LSTM(LSTM_SIZE, return_sequences=True,return_state=True,recurrent_dropout=0.2))\n",
        "_,last11,_,last12,_ = shared_lstm(shared_embedding_layer_1)\n",
        "_,last21,_,last22,_ = shared_lstm(shared_embedding_layer_2)\n",
        "concat = Concatenate()([last11,last12,last21,last22])\n",
        "out = Dense(2,activation = \"softmax\",name=\"model1\",)(concat)\n",
        "\n",
        "model = Model(inputs=[inputA,inputB],outputs=out)\n",
        "model.summary()\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1QU-Nm928liikIV4AYyrX-UOUxKStNUk_/NLP/Assignment4\n",
            "Found 400000 word vectors.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 20, 300)      3908700     input_5[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 20, 600), (N 1442400     embedding_2[0][0]                \n",
            "                                                                 embedding_2[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 1200)         0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "                                                                 bidirectional[1][1]              \n",
            "                                                                 bidirectional[1][3]              \n",
            "__________________________________________________________________________________________________\n",
            "model1 (Dense)                  (None, 2)            2402        concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 5,353,502\n",
            "Trainable params: 5,353,502\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl_huyYuqXvR",
        "colab_type": "code",
        "outputId": "6a04338e-7199-43cb-886c-827993bb9391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        }
      },
      "source": [
        "%cd /content/gdrive/My Drive/Results\n",
        "model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "filepath = \"setting_\" + \"model3\" + \".hdf5\"\n",
        "logfilepath = \"setting_\"+\"model3\" + \".csv\"\n",
        "reduce_lr_rate=0.2\n",
        "logCallback = CSVLogger(logfilepath, separator=',', append=False)\n",
        "earlyStopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=0, mode='auto')\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_weights_only=True, verbose=1,\n",
        "                             save_best_only=True, mode='auto')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=reduce_lr_rate, patience=10,\n",
        "                              cooldown=0, min_lr=0.0000000001, verbose=0)\n",
        "\n",
        "callbacks_list = [logCallback, earlyStopping, reduce_lr, checkpoint]\n",
        "model.fit([padded_X_train1,padded_X_train2],y_trainhot,epochs=100, batch_size=32,\n",
        "                verbose=1,shuffle=True,callbacks=callbacks_list,\n",
        "             validation_data=([padded_X_val1,padded_X_val2],y_valhot),use_multprocessing=True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Results\n",
            "Epoch 1/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.6140 - accuracy: 0.6881\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.69363, saving model to setting_model3.hdf5\n",
            "115/115 [==============================] - 36s 312ms/step - loss: 0.6140 - accuracy: 0.6881 - val_loss: 0.6057 - val_accuracy: 0.6936 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.3568 - accuracy: 0.8525\n",
            "Epoch 00002: val_accuracy did not improve from 0.69363\n",
            "115/115 [==============================] - 34s 296ms/step - loss: 0.3568 - accuracy: 0.8525 - val_loss: 0.8058 - val_accuracy: 0.6814 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.9656\n",
            "Epoch 00003: val_accuracy did not improve from 0.69363\n",
            "115/115 [==============================] - 34s 296ms/step - loss: 0.1081 - accuracy: 0.9656 - val_loss: 0.9525 - val_accuracy: 0.6225 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9885\n",
            "Epoch 00004: val_accuracy did not improve from 0.69363\n",
            "115/115 [==============================] - 34s 295ms/step - loss: 0.0362 - accuracy: 0.9885 - val_loss: 1.1426 - val_accuracy: 0.6054 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9935\n",
            "Epoch 00005: val_accuracy did not improve from 0.69363\n",
            "115/115 [==============================] - 34s 296ms/step - loss: 0.0279 - accuracy: 0.9935 - val_loss: 1.6110 - val_accuracy: 0.6324 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9948\n",
            "Epoch 00006: val_accuracy did not improve from 0.69363\n",
            "115/115 [==============================] - 34s 299ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 1.6825 - val_accuracy: 0.6078 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9959\n",
            "Epoch 00007: val_accuracy did not improve from 0.69363\n",
            "115/115 [==============================] - 34s 297ms/step - loss: 0.0148 - accuracy: 0.9959 - val_loss: 1.9395 - val_accuracy: 0.6201 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9978\n",
            "Epoch 00008: val_accuracy did not improve from 0.69363\n",
            "115/115 [==============================] - 34s 296ms/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 1.7748 - val_accuracy: 0.6225 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9973\n",
            "Epoch 00009: val_accuracy did not improve from 0.69363\n",
            "115/115 [==============================] - 34s 296ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 1.9200 - val_accuracy: 0.6078 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9965\n",
            "Epoch 00010: val_accuracy did not improve from 0.69363\n",
            "115/115 [==============================] - 34s 296ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 1.6696 - val_accuracy: 0.6324 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9970\n",
            "Epoch 00011: val_accuracy did not improve from 0.69363\n",
            "115/115 [==============================] - 34s 297ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 1.7104 - val_accuracy: 0.6324 - lr: 0.0010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc222122358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lreHxSS0nFY",
        "colab_type": "code",
        "outputId": "a4e71822-940d-4c60-bd67-aff253170b26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "#predictions = code here\n",
        "labelList=[0,1]\n",
        "predictions = model.predict([padded_X_test1,padded_X_test2])\n",
        "from sklearn.metrics import confusion_matrix\n",
        "predictions = np.argmax(predictions,axis=-1)\n",
        "test_Y_max=np.argmax(y_testhot, axis=-1)\n",
        "cm=confusion_matrix(test_Y_max,predictions)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "cm = pd.DataFrame(cm, labelList,labelList )# matrix,names row,names col,\n",
        "plt.figure(figsize=(10,7))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(cm, annot=True, annot_kws={\"size\": 11}, fmt=\".2f\") # font size\n",
        "plt.show()\n",
        "print(cm)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "          0         1\n",
            "0  0.371972  0.628028\n",
            "1  0.218832  0.781168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5BOJDiU0shn",
        "colab_type": "code",
        "outputId": "3fda21f8-42ef-457e-9fe4-afe915b64e02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "print(\"Classification Report\\n\",classification_report(test_Y_max, predictions, labels=[0,1], target_names = [\"Positive\",\"Negative\"]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.46      0.37      0.41       578\n",
            "    Negative       0.71      0.78      0.74      1147\n",
            "\n",
            "    accuracy                           0.64      1725\n",
            "   macro avg       0.59      0.58      0.58      1725\n",
            "weighted avg       0.63      0.64      0.63      1725\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9wE6rzwY0YN",
        "colab_type": "text"
      },
      "source": [
        "# Task 2 Sentiment Classification\n",
        "For this task we will be reusing the movie reviews dataset available on <a href=\"https://www.kaggle.com/c/word2vec-nlp-tutorial/data\">kaggle</a> and download the dataset from there. \n",
        "We will be using the unlabeledTrainData file and labeledTrainData file. We will use the gensim package to train word2vec embeddings using [gensim](https://radimrehurek.com/gensim/) package and unlabelled train data as in the previous assignmnet. Now instead for creating a single representation for each review we will be using deep learning models for this task. We will use the same archetecture as before but will experiment with different reccurant networks namely RNN, GRU and LSTM.<br> This task might feel like <a href=\"https://ibb.co/Tgh2XyH\">this</a> but since this is a deep learning assignment thus we must use it.\n",
        "<h3>Data Preperation</h3>\n",
        "<ul>\n",
        "    <li> First we need to preprocess the data, convert the data to lower casing(both files). Any other preprocessing procedures are optional but keep in mind that this will affect the performance of your model.</li>\n",
        "    <li> Split the labeledTrainData data file into test, train and validation in the ratio 20,70,10. Use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">scikit_test_train_split</a> <br><i><b>Hint:</b> use the splitter twice to get desired data splits.</i></li>\n",
        "    <li> Next we need the vocabulary, vocabulary size and to convert sentences to numeric sequences by representing each word with a numeric value which will make our implementation easier later on, use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\">Tokenizer</a> from keras. <br><i>(Fit the tokenizer on train data and use the same tokenizer to convert train,test and validation data to numeric sequences)</i> </li>\n",
        "    <li>  Use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\"> pad sequences</a> to add post padding to all sentences that are shorter than maximum sequence length</li>\n",
        "    <li> Use one hot representation for targets/labels, you can use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">scikit learn</a> or <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing\">keras preprocessing</a>.</li>\n",
        "</ul>\n",
        "<h3>Loading embeddings</h3>\n",
        "<ul>\n",
        "    <li> As state before use the gensim package to train the word2vec model on unlabelledTrainData file</li>\n",
        "    <li> Next we will create a dictionary for our dataset's vocabulary. Copy all the word embeddings for words that are in our vocabulary and in the word2vec model, if a word exists in our vocabulary but does not exist in word2vec model create a zero vector of embedding dimension size and add it to the dictionary.</li>\n",
        "</ul>\n",
        "<h3>Create Model</h3>\n",
        "<ul>\n",
        "    <li> Here is a visual for the model <img src=\"sentimentdeep.png\">\n",
        "    <li> Create the model using <a href\"https://www.tensorflow.org/guide/keras/functional\">functional API</a> or the <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\">Sequential API</a></li>\n",
        "    <li> Hints: The emebedding layer has a parameter that allows you to use pretrained embeddings</li>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ITbPsPSY0YP",
        "colab_type": "text"
      },
      "source": [
        "Use can reuse the code snippets from above for call backs, prediction heat map and classification report\n",
        "<i>You will have provide a label list for this specific dataset inorder for them to run, you are to make the required changes yourself</i>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmFSPUkWYY_K",
        "colab_type": "code",
        "outputId": "cbcc96eb-f529-4441-951b-5d82e87ee659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/gdrive/My Drive/NLP/Assignment4"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1QU-Nm928liikIV4AYyrX-UOUxKStNUk_/NLP/Assignment4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3UXkibDY0YR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dft2 = pd.read_csv(\"labeledTrainData.tsv\",sep=\"\\t\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra0hwa8WY0YV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del(dft2['id'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cih_9xqpcBf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(data):\n",
        "    \"\"\"\n",
        "    Return preprocessed data\n",
        "\n",
        "    Args:\n",
        "        data : sentence pairs\n",
        "    \n",
        "    Returns: preprocessed_data\n",
        "    preprocessed_data : preprocessed dataset \n",
        "    \"\"\"\n",
        "    #Doing the bare minimum pre-processing. Rest to be done in tokenizer/padding \n",
        "    data['review'] = data['review'].str.lower()\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqfnvanNY0YY",
        "colab_type": "code",
        "outputId": "6f1c9c46-2511-45d7-a24c-1493e79b309a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "dft2.head()\n",
        "x = dft2[['review']]\n",
        "y = dft2[['sentiment']]\n",
        "x = preprocessing(x)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx8UFpfvftAY",
        "colab_type": "code",
        "outputId": "de388025-e8f2-43c9-e127-105729d056eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "x.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>with all this stuff going down at the moment w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\the classic war of the worlds\\\" by timothy hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the film starts with a manager (nicholas bell)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>it must be assumed that those who praised this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>superbly trashy and wondrously unpretentious 8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review\n",
              "0  with all this stuff going down at the moment w...\n",
              "1  \\the classic war of the worlds\\\" by timothy hi...\n",
              "2  the film starts with a manager (nicholas bell)...\n",
              "3  it must be assumed that those who praised this...\n",
              "4  superbly trashy and wondrously unpretentious 8..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3GtCHTHZ400",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testTrainSplit1(data_X,data_Y):\n",
        "    \"\"\"\n",
        "    Return test train data\n",
        "\n",
        "    Args:\n",
        "        data_X : sentence pairs\n",
        "        data_Y: labels\n",
        "        \n",
        "    Returns: test train and validation split data \n",
        "    \"\"\"\n",
        "    #Training this bish function to do 70,20,10 split\n",
        "    X_train, X_val, y_train, y_val = train_test_split(data_X, data_Y, test_size=0.1, random_state=1)\n",
        "    X_train,X_test,y_train,y_test = train_test_split(data_X,data_Y,test_size=0.22,random_state=1) #0.22*0.9 ~= 20 percent of original data. Consecutive discount  \n",
        "    return X_train,X_test,X_val,y_train,y_test,y_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9PHLYO7bv1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,X_val,y_train,y_test,y_val = testTrainSplit1(x,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVQYJkf4clsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combineList(X):\n",
        "    #Joining the sentences into a list of list \n",
        "    slist = []\n",
        "    for val in X['review']:\n",
        "        slist.append(str(val))\n",
        "    return slist\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfqD83QDd7bO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_list = combineList(X_train)\n",
        "X_test_list = combineList(X_test)\n",
        "X_val_list = combineList(X_val)\n",
        "y_trainhot = to_categorical(y_train)\n",
        "y_testhot = to_categorical(y_test)\n",
        "y_valhot = to_categorical(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQock5l8eJIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_X_train,padded_X_test,padded_X_val,vocab,vocab_size = doMagic(X_train_list,X_test_list,X_val_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZfHHrblhtzx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5520a5b5-d838-4b87-f3ea-7789b4873f65"
      },
      "source": [
        "unlabeledTrain = pd.read_csv(\"unlabeledTrainData.tsv\",sep=\"\\t\",error_bad_lines=False)\n",
        "unlabeledTrain.head()\n",
        "del unlabeledTrain['id']\n",
        "unlabeledTrain = preprocessing(unlabeledTrain)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 43043: expected 2 fields, saw 3\\n'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0Bhdjbd33Xj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "b74ec0d0-f34c-4b7d-e116-9ed7b6eb98c6"
      },
      "source": [
        "len(unlabeledTrain)\n",
        "unlabeledTrain.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>watching time chasers, it obvious that it was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i saw this film about 20 years ago and remembe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>minor spoilers&lt;br /&gt;&lt;br /&gt;in new york, joan ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i went to see this film with a great deal of e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yes, i agree with everyone on this site this m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review\n",
              "0  watching time chasers, it obvious that it was ...\n",
              "1  i saw this film about 20 years ago and remembe...\n",
              "2  minor spoilers<br /><br />in new york, joan ba...\n",
              "3  i went to see this film with a great deal of e...\n",
              "4  yes, i agree with everyone on this site this m..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05_MbWTV4jLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "listdata = unlabeledTrain['review'].str.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThuZ55RS4503",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combineList = []\n",
        "for review in listdata:\n",
        "  combineList.append(review)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJSGNa3U4Ef0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "EMBEDING_DIM = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-ji588p4H9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66151425-a6ab-46d7-a9b9-bfb2da7e0c02"
      },
      "source": [
        "wordVecModel = Word2Vec(combineList,size=EMBEDING_DIM)\n",
        "words = list(wordVecModel.wv.vocab) #dictionary of wordvec model is words \n",
        "%cd /content/gdrive/My Drive/Results"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiE7qRlJ62ZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeedingDict = {}\n",
        "for word in words:\n",
        "  embeedingDict[word] = wordVecModel.wv.get_vector(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MggI0iPpG254",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HinPO6oGMIIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadEmbeedings(word_index,embeddings_index):\n",
        "  embedding_matrix = np.zeros((len(word_index) + 1, EMBEDING_DIM))\n",
        "  for word, i in word_index.items():\n",
        "      embedding_vector = embeddings_index.get(word)\n",
        "      if embedding_vector is not None:\n",
        "          # words not found in embedding index will be all-zeros.\n",
        "          embedding_matrix[i] = embedding_vector\n",
        "\n",
        "  print('Found %s word vectors.' % len(embeddings_index))\n",
        "  return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEbe22hvLsK0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d20e795-ffee-49e3-993e-cab71db74a3e"
      },
      "source": [
        "embeeding_matrix = loadEmbeedings(vocab,embeedingDict)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 72507 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ1jWbfrMVey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86518393-f41d-41e5-b39f-068e651d38e2"
      },
      "source": [
        "y_trainhot.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19500, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLr2qcihH4Gs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "b52582ef-303c-443d-ca0b-5c4ce87eb231"
      },
      "source": [
        "# code model here\n",
        "%cd /content/gdrive/My Drive/NLP/Assignment4\n",
        "LSTM_SIZE = 50\n",
        "maxlen = 20\n",
        "inputA = Input(shape=(maxlen,))\n",
        "embedding_layer = Embedding(input_dim=vocab_size,output_dim=EMBEDING_DIM,input_length=maxlen,weights=[embeeding_matrix],\n",
        "                           trainable=True)(inputA)\n",
        "\n",
        "_,last1,_ = LSTM(LSTM_SIZE, return_sequences=True,return_state=True,recurrent_dropout=0.2)(embedding_layer)\n",
        "out = Dense(2,activation = \"softmax\",name=\"model4\",)(last1)\n",
        "\n",
        "model = Model(inputs=inputA,outputs=out)\n",
        "model.summary()\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1QU-Nm928liikIV4AYyrX-UOUxKStNUk_/NLP/Assignment4\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 20, 50)            3970050   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                [(None, 20, 50), (None, 5 20200     \n",
            "_________________________________________________________________\n",
            "model4 (Dense)               (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 3,990,352\n",
            "Trainable params: 3,990,352\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK2e3XwQOMIV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "49cf7eba-1d87-46ee-f76b-dd3a5f12b342"
      },
      "source": [
        "%cd /content/gdrive/My Drive/Results\n",
        "model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "filepath = \"setting_\" + \"model4\" + \".hdf5\"\n",
        "logfilepath = \"setting_\"+\"model4\" + \".csv\"\n",
        "reduce_lr_rate=0.2\n",
        "logCallback = CSVLogger(logfilepath, separator=',', append=False)\n",
        "earlyStopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=0, mode='auto')\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_weights_only=True, verbose=1,\n",
        "                             save_best_only=True, mode='auto')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=reduce_lr_rate, patience=10,\n",
        "                              cooldown=0, min_lr=0.0000000001, verbose=0)\n",
        "\n",
        "callbacks_list = [logCallback, earlyStopping, reduce_lr, checkpoint]\n",
        "model.fit(padded_X_train,y_trainhot,epochs=100, batch_size=32,\n",
        "                verbose=1,shuffle=True,callbacks=callbacks_list,\n",
        "             validation_data=(padded_X_val,y_valhot),use_multprocessing=True)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Results\n",
            "Epoch 1/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.5284 - accuracy: 0.7256\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.76640, saving model to setting_model4.hdf5\n",
            "610/610 [==============================] - 66s 108ms/step - loss: 0.5284 - accuracy: 0.7256 - val_loss: 0.4839 - val_accuracy: 0.7664 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.3414 - accuracy: 0.8503\n",
            "Epoch 00002: val_accuracy did not improve from 0.76640\n",
            "610/610 [==============================] - 63s 103ms/step - loss: 0.3414 - accuracy: 0.8503 - val_loss: 0.5250 - val_accuracy: 0.7612 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9150\n",
            "Epoch 00003: val_accuracy did not improve from 0.76640\n",
            "610/610 [==============================] - 62s 102ms/step - loss: 0.2151 - accuracy: 0.9150 - val_loss: 0.6520 - val_accuracy: 0.7392 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.1369 - accuracy: 0.9476\n",
            "Epoch 00004: val_accuracy did not improve from 0.76640\n",
            "610/610 [==============================] - 62s 101ms/step - loss: 0.1369 - accuracy: 0.9476 - val_loss: 0.8062 - val_accuracy: 0.7368 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9683\n",
            "Epoch 00005: val_accuracy did not improve from 0.76640\n",
            "610/610 [==============================] - 62s 101ms/step - loss: 0.0865 - accuracy: 0.9683 - val_loss: 0.9782 - val_accuracy: 0.7236 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9799\n",
            "Epoch 00006: val_accuracy did not improve from 0.76640\n",
            "610/610 [==============================] - 61s 101ms/step - loss: 0.0554 - accuracy: 0.9799 - val_loss: 1.0971 - val_accuracy: 0.7204 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9877\n",
            "Epoch 00007: val_accuracy did not improve from 0.76640\n",
            "610/610 [==============================] - 61s 100ms/step - loss: 0.0368 - accuracy: 0.9877 - val_loss: 1.3023 - val_accuracy: 0.7192 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9908\n",
            "Epoch 00008: val_accuracy did not improve from 0.76640\n",
            "610/610 [==============================] - 61s 100ms/step - loss: 0.0269 - accuracy: 0.9908 - val_loss: 1.4771 - val_accuracy: 0.7232 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9919\n",
            "Epoch 00009: val_accuracy did not improve from 0.76640\n",
            "610/610 [==============================] - 62s 101ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 1.6158 - val_accuracy: 0.7156 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9952\n",
            "Epoch 00010: val_accuracy did not improve from 0.76640\n",
            "610/610 [==============================] - 61s 101ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 1.8848 - val_accuracy: 0.7184 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9958\n",
            "Epoch 00011: val_accuracy did not improve from 0.76640\n",
            "610/610 [==============================] - 62s 101ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 1.9073 - val_accuracy: 0.7196 - lr: 0.0010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc1bd2e00f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbIdre-rU8n1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "54a19f5c-2fd8-4f47-af35-156f7c55e923"
      },
      "source": [
        "#predictions = code here\n",
        "labelList=[0,1]\n",
        "predictions = model.predict(padded_X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "predictions = np.argmax(predictions,axis=-1)\n",
        "test_Y_max=np.argmax(y_testhot, axis=-1)\n",
        "cm=confusion_matrix(test_Y_max,predictions)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "cm = pd.DataFrame(cm, labelList,labelList )# matrix,names row,names col,\n",
        "plt.figure(figsize=(10,7))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(cm, annot=True, annot_kws={\"size\": 11}, fmt=\".2f\") # font size\n",
        "plt.show()\n",
        "print(cm)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "          0         1\n",
            "0  0.740527  0.259473\n",
            "1  0.303774  0.696226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSFxqX6eVKXe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "7f9b5567-a95a-4700-9d16-a9a12d0f2be8"
      },
      "source": [
        "print(\"Classification Report\\n\",classification_report(test_Y_max, predictions, labels=[0,1], target_names = [\"Positive\",\"Negative\"]))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.71      0.74      0.73      2771\n",
            "    Negative       0.73      0.70      0.71      2729\n",
            "\n",
            "    accuracy                           0.72      5500\n",
            "   macro avg       0.72      0.72      0.72      5500\n",
            "weighted avg       0.72      0.72      0.72      5500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlL9oDl3UVTd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "cee0f30f-070f-4319-c4c7-ac233a675f96"
      },
      "source": [
        "# code model here\n",
        "%cd /content/gdrive/My Drive/NLP/Assignment4\n",
        "LSTM_SIZE = 50\n",
        "maxlen = 20\n",
        "inputA = Input(shape=(maxlen,))\n",
        "embedding_layer = Embedding(input_dim=vocab_size,output_dim=EMBEDING_DIM,input_length=maxlen,weights=[embeeding_matrix],\n",
        "                           trainable=True)\n",
        "shared_embedding_layer_1 = embedding_layer(inputA)\n",
        "\n",
        "shared_lstm = GRU(LSTM_SIZE, return_sequences=True,return_state=True,recurrent_dropout=0.2)\n",
        "_,last1 = shared_lstm(shared_embedding_layer_1)\n",
        "out = Dense(2,activation = \"softmax\",name=\"model5\",)(last1)\n",
        "\n",
        "model = Model(inputs=inputA,outputs=out)\n",
        "model.summary()\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1QU-Nm928liikIV4AYyrX-UOUxKStNUk_/NLP/Assignment4\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 20, 50)            3970050   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    [(None, 20, 50), (None, 5 15300     \n",
            "_________________________________________________________________\n",
            "model5 (Dense)               (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 3,985,452\n",
            "Trainable params: 3,985,452\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohRkX_aEU7PY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "7bb206a6-8a7d-4910-f758-8e303b92aec1"
      },
      "source": [
        "%cd /content/gdrive/My Drive/Results\n",
        "model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "filepath = \"setting_\" + \"model5\" + \".hdf5\"\n",
        "logfilepath = \"setting_\"+\"model5\" + \".csv\"\n",
        "reduce_lr_rate=0.2\n",
        "logCallback = CSVLogger(logfilepath, separator=',', append=False)\n",
        "earlyStopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=0, mode='auto')\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_weights_only=True, verbose=1,\n",
        "                             save_best_only=True, mode='auto')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=reduce_lr_rate, patience=10,\n",
        "                              cooldown=0, min_lr=0.0000000001, verbose=0)\n",
        "\n",
        "callbacks_list = [logCallback, earlyStopping, reduce_lr, checkpoint]\n",
        "model.fit(padded_X_train,y_trainhot,epochs=100, batch_size=32,\n",
        "                verbose=1,shuffle=True,callbacks=callbacks_list,\n",
        "             validation_data=(padded_X_val,y_valhot),use_multprocessing=True)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Results\n",
            "Epoch 1/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.7230\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.77800, saving model to setting_model5.hdf5\n",
            "610/610 [==============================] - 60s 98ms/step - loss: 0.5328 - accuracy: 0.7230 - val_loss: 0.4706 - val_accuracy: 0.7780 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.3408 - accuracy: 0.8493\n",
            "Epoch 00002: val_accuracy did not improve from 0.77800\n",
            "610/610 [==============================] - 59s 96ms/step - loss: 0.3408 - accuracy: 0.8493 - val_loss: 0.5115 - val_accuracy: 0.7616 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.2236 - accuracy: 0.9114\n",
            "Epoch 00003: val_accuracy did not improve from 0.77800\n",
            "610/610 [==============================] - 58s 96ms/step - loss: 0.2236 - accuracy: 0.9114 - val_loss: 0.6103 - val_accuracy: 0.7520 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.1464 - accuracy: 0.9445\n",
            "Epoch 00004: val_accuracy did not improve from 0.77800\n",
            "610/610 [==============================] - 59s 96ms/step - loss: 0.1464 - accuracy: 0.9445 - val_loss: 0.7349 - val_accuracy: 0.7444 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9635\n",
            "Epoch 00005: val_accuracy did not improve from 0.77800\n",
            "610/610 [==============================] - 59s 96ms/step - loss: 0.1027 - accuracy: 0.9635 - val_loss: 0.8548 - val_accuracy: 0.7304 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9747\n",
            "Epoch 00006: val_accuracy did not improve from 0.77800\n",
            "610/610 [==============================] - 58s 95ms/step - loss: 0.0726 - accuracy: 0.9747 - val_loss: 1.0160 - val_accuracy: 0.7252 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9810\n",
            "Epoch 00007: val_accuracy did not improve from 0.77800\n",
            "610/610 [==============================] - 58s 95ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 1.1505 - val_accuracy: 0.7316 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9872\n",
            "Epoch 00008: val_accuracy did not improve from 0.77800\n",
            "610/610 [==============================] - 58s 95ms/step - loss: 0.0372 - accuracy: 0.9872 - val_loss: 1.1804 - val_accuracy: 0.7220 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9917\n",
            "Epoch 00009: val_accuracy did not improve from 0.77800\n",
            "610/610 [==============================] - 58s 96ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 1.4752 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9931\n",
            "Epoch 00010: val_accuracy did not improve from 0.77800\n",
            "610/610 [==============================] - 58s 95ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 1.6710 - val_accuracy: 0.7208 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9962\n",
            "Epoch 00011: val_accuracy did not improve from 0.77800\n",
            "610/610 [==============================] - 58s 95ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 1.6260 - val_accuracy: 0.7128 - lr: 0.0010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc1bc4df9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pins1J1xVVaL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "45b43285-bab1-46c2-ec6a-74df7f5fc72d"
      },
      "source": [
        "#predictions = code here\n",
        "labelList=[0,1]\n",
        "predictions = model.predict(padded_X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "predictions = np.argmax(predictions,axis=-1)\n",
        "test_Y_max=np.argmax(y_testhot, axis=-1)\n",
        "cm=confusion_matrix(test_Y_max,predictions)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "cm = pd.DataFrame(cm, labelList,labelList )# matrix,names row,names col,\n",
        "plt.figure(figsize=(10,7))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(cm, annot=True, annot_kws={\"size\": 11}, fmt=\".2f\") # font size\n",
        "plt.show()\n",
        "print(cm)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "          0         1\n",
            "0  0.771923  0.228077\n",
            "1  0.347014  0.652986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7QvsyrdVhH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "abb574cf-fce2-4408-9e65-54b220c3591a"
      },
      "source": [
        "print(\"Classification Report\\n\",classification_report(test_Y_max, predictions, labels=[0,1], target_names = [\"Positive\",\"Negative\"]))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.69      0.77      0.73      2771\n",
            "    Negative       0.74      0.65      0.69      2729\n",
            "\n",
            "    accuracy                           0.71      5500\n",
            "   macro avg       0.72      0.71      0.71      5500\n",
            "weighted avg       0.72      0.71      0.71      5500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4L2Jaa8WBBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "036b099b-2a5e-4156-940a-a0946ea17ca9"
      },
      "source": [
        "# code model here\n",
        "%cd /content/gdrive/My Drive/NLP/Assignment4\n",
        "LSTM_SIZE = 50\n",
        "maxlen = 20\n",
        "inputA = Input(shape=(maxlen,))\n",
        "embedding_layer = Embedding(input_dim=vocab_size,output_dim=EMBEDING_DIM,input_length=maxlen,weights=[embeeding_matrix],\n",
        "                           trainable=True)\n",
        "shared_embedding_layer_1 = embedding_layer(inputA)\n",
        "\n",
        "shared_lstm = SimpleRNN(LSTM_SIZE, return_sequences=True,return_state=True,recurrent_dropout=0.2)\n",
        "_,last1 = shared_lstm(shared_embedding_layer_1)\n",
        "out = Dense(2,activation = \"softmax\",name=\"model6\",)(last1)\n",
        "\n",
        "model = Model(inputs=inputA,outputs=out)\n",
        "model.summary()\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1QU-Nm928liikIV4AYyrX-UOUxKStNUk_/NLP/Assignment4\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_6 (Embedding)      (None, 20, 50)            3970050   \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       [(None, 20, 50), (None, 5 5050      \n",
            "_________________________________________________________________\n",
            "model6 (Dense)               (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 3,975,202\n",
            "Trainable params: 3,975,202\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5HdNoS2XM1E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "outputId": "b0c7fc9f-6b1c-4601-fd35-e8668b4d4615"
      },
      "source": [
        "%cd /content/gdrive/My Drive/Results\n",
        "model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "filepath = \"setting_\" + \"model6\" + \".hdf5\"\n",
        "logfilepath = \"setting_\"+\"model6\" + \".csv\"\n",
        "reduce_lr_rate=0.2\n",
        "logCallback = CSVLogger(logfilepath, separator=',', append=False)\n",
        "earlyStopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=0, mode='auto')\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_weights_only=True, verbose=1,\n",
        "                             save_best_only=True, mode='auto')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=reduce_lr_rate, patience=10,\n",
        "                              cooldown=0, min_lr=0.0000000001, verbose=0)\n",
        "\n",
        "callbacks_list = [logCallback, earlyStopping, reduce_lr, checkpoint]\n",
        "model.fit(padded_X_train,y_trainhot,epochs=100, batch_size=32,\n",
        "                verbose=1,shuffle=True,callbacks=callbacks_list,\n",
        "             validation_data=(padded_X_val,y_valhot),use_multprocessing=True)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Results\n",
            "Epoch 1/100\n",
            "609/610 [============================>.] - ETA: 0s - loss: 0.5884 - accuracy: 0.6691\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.76160, saving model to setting_model6.hdf5\n",
            "610/610 [==============================] - 34s 57ms/step - loss: 0.5882 - accuracy: 0.6691 - val_loss: 0.4950 - val_accuracy: 0.7616 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.3956 - accuracy: 0.8243\n",
            "Epoch 00002: val_accuracy improved from 0.76160 to 0.77280, saving model to setting_model6.hdf5\n",
            "610/610 [==============================] - 34s 55ms/step - loss: 0.3956 - accuracy: 0.8243 - val_loss: 0.5153 - val_accuracy: 0.7728 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.2764 - accuracy: 0.8886\n",
            "Epoch 00003: val_accuracy did not improve from 0.77280\n",
            "610/610 [==============================] - 33s 54ms/step - loss: 0.2764 - accuracy: 0.8886 - val_loss: 0.6060 - val_accuracy: 0.7420 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.9233\n",
            "Epoch 00004: val_accuracy did not improve from 0.77280\n",
            "610/610 [==============================] - 33s 53ms/step - loss: 0.2021 - accuracy: 0.9233 - val_loss: 0.6645 - val_accuracy: 0.7376 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9438\n",
            "Epoch 00005: val_accuracy did not improve from 0.77280\n",
            "610/610 [==============================] - 33s 54ms/step - loss: 0.1540 - accuracy: 0.9438 - val_loss: 0.6899 - val_accuracy: 0.7316 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.9593\n",
            "Epoch 00006: val_accuracy did not improve from 0.77280\n",
            "610/610 [==============================] - 34s 55ms/step - loss: 0.1161 - accuracy: 0.9593 - val_loss: 1.0685 - val_accuracy: 0.7360 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "609/610 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.9662\n",
            "Epoch 00007: val_accuracy did not improve from 0.77280\n",
            "610/610 [==============================] - 33s 55ms/step - loss: 0.0942 - accuracy: 0.9663 - val_loss: 1.0339 - val_accuracy: 0.7376 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "609/610 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 0.9718\n",
            "Epoch 00008: val_accuracy did not improve from 0.77280\n",
            "610/610 [==============================] - 33s 54ms/step - loss: 0.0760 - accuracy: 0.9718 - val_loss: 1.0025 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9754\n",
            "Epoch 00009: val_accuracy did not improve from 0.77280\n",
            "610/610 [==============================] - 33s 54ms/step - loss: 0.0690 - accuracy: 0.9754 - val_loss: 1.1513 - val_accuracy: 0.7292 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9811\n",
            "Epoch 00010: val_accuracy did not improve from 0.77280\n",
            "610/610 [==============================] - 33s 54ms/step - loss: 0.0554 - accuracy: 0.9811 - val_loss: 1.3325 - val_accuracy: 0.7320 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9839\n",
            "Epoch 00011: val_accuracy did not improve from 0.77280\n",
            "610/610 [==============================] - 32s 53ms/step - loss: 0.0467 - accuracy: 0.9839 - val_loss: 1.4144 - val_accuracy: 0.7176 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "610/610 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9904\n",
            "Epoch 00012: val_accuracy did not improve from 0.77280\n",
            "610/610 [==============================] - 32s 53ms/step - loss: 0.0284 - accuracy: 0.9904 - val_loss: 1.3376 - val_accuracy: 0.7264 - lr: 2.0000e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc1bb6040b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFidx_IMXTOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "c65b25d5-b82a-4407-e52a-edd2c8e7c8bf"
      },
      "source": [
        "#predictions = code here\n",
        "labelList=[0,1]\n",
        "predictions = model.predict(padded_X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "predictions = np.argmax(predictions,axis=-1)\n",
        "test_Y_max=np.argmax(y_testhot, axis=-1)\n",
        "cm=confusion_matrix(test_Y_max,predictions)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "cm = pd.DataFrame(cm, labelList,labelList )# matrix,names row,names col,\n",
        "plt.figure(figsize=(10,7))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(cm, annot=True, annot_kws={\"size\": 11}, fmt=\".2f\") # font size\n",
        "plt.show()\n",
        "print(cm)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "          0         1\n",
            "0  0.720318  0.279682\n",
            "1  0.268230  0.731770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyNmIS9lXWMi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "b0cb6dd3-ebc8-4f99-b19a-07878cfe2345"
      },
      "source": [
        "print(\"Classification Report\\n\",classification_report(test_Y_max, predictions, labels=[0,1], target_names = [\"Positive\",\"Negative\"]))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.73      0.72      0.73      2771\n",
            "    Negative       0.72      0.73      0.73      2729\n",
            "\n",
            "    accuracy                           0.73      5500\n",
            "   macro avg       0.73      0.73      0.73      5500\n",
            "weighted avg       0.73      0.73      0.73      5500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B37hEJGm7OA",
        "colab_type": "text"
      },
      "source": [
        "`Ckearly Simple RNN has slightly more accuracy than LSTM and GRU`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgAmib7CY0Yd",
        "colab_type": "text"
      },
      "source": [
        "# We hope all of you are working on your projects and <a href=\"https://ibb.co/dcpf4vS\"> Kudos for completing the assingnment</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fPz6SkqgLhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}